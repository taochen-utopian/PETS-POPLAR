{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvzf en_core_web_sm-3.4.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "swedish-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tracked-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mt = pd.read_csv(\"/ssd003/projects/pets/datasets/mtsamples.csv\")\n",
    "\n",
    "df_mt_X = df_mt[[\"description\",'sample_name', 'transcription', 'keywords']]\n",
    "df_mt_Y = df_mt[\"medical_specialty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "august-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_mt_X, df_mt_Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "architectural-saturday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3999</td>\n",
       "      <td>3999</td>\n",
       "      <td>3973</td>\n",
       "      <td>3145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2239</td>\n",
       "      <td>2265</td>\n",
       "      <td>2246</td>\n",
       "      <td>3079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>An example/template for a routine normal male...</td>\n",
       "      <td>Hematuria - ER Visit</td>\n",
       "      <td>REASON FOR CONSULTATION: , Thyroid mass diagno...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description  \\\n",
       "count                                                3999   \n",
       "unique                                               2239   \n",
       "top      An example/template for a routine normal male...   \n",
       "freq                                                   10   \n",
       "\n",
       "                   sample_name  \\\n",
       "count                     3999   \n",
       "unique                    2265   \n",
       "top      Hematuria - ER Visit    \n",
       "freq                         4   \n",
       "\n",
       "                                            transcription keywords  \n",
       "count                                                3973     3145  \n",
       "unique                                               2246     3079  \n",
       "top     REASON FOR CONSULTATION: , Thyroid mass diagno...           \n",
       "freq                                                    4       65  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "hollywood-details",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medical_specialty\n",
       " Surgery                          872\n",
       " Consult - History and Phy.       409\n",
       " Cardiovascular / Pulmonary       303\n",
       " Orthopedic                       287\n",
       " General Medicine                 209\n",
       " Radiology                        205\n",
       " Gastroenterology                 188\n",
       " Neurology                        179\n",
       " SOAP / Chart / Progress Notes    139\n",
       " Obstetrics / Gynecology          125\n",
       " Urology                          121\n",
       " Discharge Summary                 87\n",
       " Neurosurgery                      76\n",
       " Hematology - Oncology             75\n",
       " ENT - Otolaryngology              73\n",
       " Nephrology                        66\n",
       " Ophthalmology                     65\n",
       " Emergency Room Reports            58\n",
       " Pediatrics - Neonatal             55\n",
       " Pain Management                   53\n",
       " Psychiatry / Psychology           46\n",
       " Podiatry                          42\n",
       " Office Notes                      40\n",
       " Dermatology                       26\n",
       " Cosmetic / Plastic Surgery        23\n",
       " Letters                           22\n",
       " Dentistry                         19\n",
       " Sleep Medicine                    18\n",
       " Endocrinology                     16\n",
       " Bariatrics                        15\n",
       " IME-QME-Work Comp etc.            15\n",
       " Physical Medicine - Rehab         14\n",
       " Chiropractic                      13\n",
       " Speech - Language                  9\n",
       " Diets and Nutritions               9\n",
       " Lab Medicine - Pathology           7\n",
       " Autopsy                            6\n",
       " Allergy / Immunology               6\n",
       " Hospice - Palliative Care          4\n",
       " Rheumatology                       4\n",
       "Name: medical_specialty, dtype: int64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.groupby(y_train).count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "incorporated-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "proper-addition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"EXAM:,  Mammographic screening FFDM,HISTORY: , 40-year-old female who is on oral contraceptive pills.  She has no present symptomatic complaints.  No prior history of breast surgery nor family history of breast CA.,TECHNIQUE: , Standard CC and MLO views of the breasts.,COMPARISON: , This is the patient's baseline study.,FINDINGS: , The breasts are composed of moderately to significantly dense fibroglandular tissue.  The overlying skin is unremarkable.,There are a tiny cluster of calcifications in the right breast, near the central position associated with 11:30 on a clock.,There are benign-appearing calcifications in both breasts as well as unremarkable axillary lymph nodes.,There are no spiculated masses or architectural distortion.,IMPRESSION:,  Tiny cluster of calcifications at the 11:30 position of the right breast.  Recommend additional views; spot magnification in the MLO and CC views of the right breast.,BIRADS Classification 0 - Incomplete,MAMMOGRAPHY INFORMATION:,1.  A certain percentage of cancers, probably 10% to 15%, will not be identified by mammography.,2.  Lack of radiographic evidence of malignancy should not delay a biopsy if a clinically suspicious mass is present.,3.  These images were obtained with FDA-approved digital mammography equipment, and iCAD Second Look Software Version 7.2 was utilized.\""
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"transcription\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "casual-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"../en_core_web_sm-3.4.0/en_core_web_sm/en_core_web_sm-3.4.0/\", \n",
    "                 disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "acoustic-label",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Radiology'"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "literary-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(X_train[\"transcription\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "conditional-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# vocab = Counter()\n",
    "\n",
    "# def compile_vocab(s):\n",
    "#     vocab.update(Counter([t.text for t in nlp(s.lower())]))\n",
    "# X_train[~X_train[\"transcription\"].isna()][\"transcription\"].apply(compile_vocab)\n",
    "# len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "purple-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "# with open(\"../stopwords/english\") as fin:\n",
    "#     stopwords = {l.strip() for l in fin}\n",
    "    \n",
    "# for s in stopwords:\n",
    "#     vocab.pop(s, None)\n",
    "    \n",
    "# for c in string.punctuation:\n",
    "#     vocab.pop(c, None)\n",
    "    \n",
    "# vocab.pop(' ', None)\n",
    "\n",
    "# len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "brown-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./vocab_all.txt\", \"w\", encoding=\"utf-8\") as fout:\n",
    "#     for k,c in vocab.items():\n",
    "#         fout.write(f\"{k}:{c}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "marked-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# vocab = Counter()\n",
    "\n",
    "# with open(\"./vocab_all.txt\", encoding=\"utf-8\") as fin:\n",
    "#     for l in fin:\n",
    "#         vv = l.split(':')\n",
    "#         w = ':'.join(vv[:-1])\n",
    "#         c = int(vv[-1])\n",
    "#         vocab[w]= c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "extensive-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = {}\n",
    "with open(\"../glove.6B.100d.txt\", encoding=\"utf-8\") as fin:\n",
    "    for l in fin:\n",
    "        vv = l.split(' ')\n",
    "        v = list(map(float, vv[-100:]))\n",
    "        w = ' '.join(vv[:-100])\n",
    "        glove[w]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "union-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab1000 = vocab.most_common(1000)\n",
    "# vocab1000 = {v[0]:i for i,v in enumerate(vocab1000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "champion-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def word_vector(s):\n",
    "    embedding = np.zeros(100)\n",
    "    if not pd.isna(s):\n",
    "        v = [glove[t.text] for t in nlp(s.lower()) if t.text in glove]\n",
    "        embedding = np.array(v).mean(axis=0)\n",
    "    return embedding\n",
    "\n",
    "X = np.stack(X_train[\"transcription\"].apply(word_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "directed-retail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999, 100)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "handy-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = pd.Series(y_train.groupby(y_train).count().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "collaborative-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(v):\n",
    "    return lbl[lbl==v].index[0]\n",
    "\n",
    "Y = y_train.apply(f).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "still-platform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999,)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "confirmed-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "chinese-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLR(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_features, n_classes):\n",
    "        super(MLR, self).__init__()\n",
    "        self.lr = torch.nn.Linear(n_features, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.special.log_softmax(self.lr(x), 0)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "governing-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLR(X.shape[1], max(Y)+1)\n",
    "\n",
    "optim = torch.optim.SGD(model.parameters(), lr=10)\n",
    "# use Binary Cross Entropy Loss\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "separate-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.from_numpy(X).float()\n",
    "y_train_tensor = torch.from_numpy(Y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "expired-discovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1000: 6.725808143615723, correct predicted: 1697\n",
      "Loss at epoch 2000: 6.725768566131592, correct predicted: 1697\n",
      "Loss at epoch 3000: 6.725728511810303, correct predicted: 1697\n",
      "Loss at epoch 4000: 6.725689888000488, correct predicted: 1697\n",
      "Loss at epoch 5000: 6.725651264190674, correct predicted: 1697\n",
      "Loss at epoch 6000: 6.725613117218018, correct predicted: 1697\n",
      "Loss at epoch 7000: 6.7255754470825195, correct predicted: 1697\n",
      "Loss at epoch 8000: 6.725536823272705, correct predicted: 1697\n",
      "Loss at epoch 9000: 6.725498676300049, correct predicted: 1697\n",
      "Loss at epoch 10000: 6.725460529327393, correct predicted: 1697\n",
      "Loss at epoch 11000: 6.725424289703369, correct predicted: 1697\n",
      "Loss at epoch 12000: 6.725387096405029, correct predicted: 1697\n",
      "Loss at epoch 13000: 6.7253499031066895, correct predicted: 1697\n",
      "Loss at epoch 14000: 6.725313186645508, correct predicted: 1697\n",
      "Loss at epoch 15000: 6.72527551651001, correct predicted: 1697\n",
      "Loss at epoch 16000: 6.725240230560303, correct predicted: 1698\n",
      "Loss at epoch 17000: 6.725204944610596, correct predicted: 1698\n",
      "Loss at epoch 18000: 6.725168704986572, correct predicted: 1698\n",
      "Loss at epoch 19000: 6.725131988525391, correct predicted: 1698\n",
      "Loss at epoch 20000: 6.725096225738525, correct predicted: 1698\n",
      "Loss at epoch 21000: 6.725061416625977, correct predicted: 1698\n",
      "Loss at epoch 22000: 6.7250261306762695, correct predicted: 1698\n",
      "Loss at epoch 23000: 6.724991798400879, correct predicted: 1698\n",
      "Loss at epoch 24000: 6.724956035614014, correct predicted: 1699\n",
      "Loss at epoch 25000: 6.724921226501465, correct predicted: 1699\n",
      "Loss at epoch 26000: 6.724887847900391, correct predicted: 1699\n",
      "Loss at epoch 27000: 6.724852561950684, correct predicted: 1699\n",
      "Loss at epoch 28000: 6.724819183349609, correct predicted: 1699\n",
      "Loss at epoch 29000: 6.7247843742370605, correct predicted: 1699\n",
      "Loss at epoch 30000: 6.7247514724731445, correct predicted: 1699\n",
      "Loss at epoch 31000: 6.724717140197754, correct predicted: 1699\n",
      "Loss at epoch 32000: 6.724684238433838, correct predicted: 1699\n",
      "Loss at epoch 33000: 6.724649906158447, correct predicted: 1699\n",
      "Loss at epoch 34000: 6.724618434906006, correct predicted: 1699\n",
      "Loss at epoch 35000: 6.724585056304932, correct predicted: 1699\n",
      "Loss at epoch 36000: 6.724552631378174, correct predicted: 1699\n",
      "Loss at epoch 37000: 6.724519729614258, correct predicted: 1699\n",
      "Loss at epoch 38000: 6.724488258361816, correct predicted: 1699\n",
      "Loss at epoch 39000: 6.7244553565979, correct predicted: 1699\n",
      "Loss at epoch 40000: 6.724424362182617, correct predicted: 1699\n",
      "Loss at epoch 41000: 6.724392414093018, correct predicted: 1699\n",
      "Loss at epoch 42000: 6.724360466003418, correct predicted: 1699\n",
      "Loss at epoch 43000: 6.724328517913818, correct predicted: 1699\n",
      "Loss at epoch 44000: 6.724296569824219, correct predicted: 1699\n",
      "Loss at epoch 45000: 6.724266529083252, correct predicted: 1699\n",
      "Loss at epoch 46000: 6.724234580993652, correct predicted: 1699\n",
      "Loss at epoch 47000: 6.724205017089844, correct predicted: 1699\n",
      "Loss at epoch 48000: 6.724173545837402, correct predicted: 1700\n",
      "Loss at epoch 49000: 6.724143028259277, correct predicted: 1700\n",
      "Loss at epoch 50000: 6.724112033843994, correct predicted: 1700\n",
      "Loss at epoch 51000: 6.7240824699401855, correct predicted: 1700\n",
      "Loss at epoch 52000: 6.724051475524902, correct predicted: 1700\n",
      "Loss at epoch 53000: 6.724022388458252, correct predicted: 1700\n",
      "Loss at epoch 54000: 6.723991870880127, correct predicted: 1701\n",
      "Loss at epoch 55000: 6.723962306976318, correct predicted: 1701\n",
      "Loss at epoch 56000: 6.723932266235352, correct predicted: 1701\n",
      "Loss at epoch 57000: 6.723903656005859, correct predicted: 1701\n",
      "Loss at epoch 58000: 6.723874092102051, correct predicted: 1701\n",
      "Loss at epoch 59000: 6.723845481872559, correct predicted: 1701\n",
      "Loss at epoch 60000: 6.723816394805908, correct predicted: 1701\n",
      "Loss at epoch 61000: 6.723787307739258, correct predicted: 1701\n",
      "Loss at epoch 62000: 6.723758220672607, correct predicted: 1701\n",
      "Loss at epoch 63000: 6.723729610443115, correct predicted: 1701\n",
      "Loss at epoch 64000: 6.723701477050781, correct predicted: 1701\n",
      "Loss at epoch 65000: 6.7236738204956055, correct predicted: 1701\n",
      "Loss at epoch 66000: 6.723644256591797, correct predicted: 1701\n",
      "Loss at epoch 67000: 6.7236175537109375, correct predicted: 1701\n",
      "Loss at epoch 68000: 6.723588466644287, correct predicted: 1701\n",
      "Loss at epoch 69000: 6.723560810089111, correct predicted: 1701\n",
      "Loss at epoch 70000: 6.723534107208252, correct predicted: 1701\n",
      "Loss at epoch 71000: 6.723505973815918, correct predicted: 1701\n",
      "Loss at epoch 72000: 6.723477840423584, correct predicted: 1701\n",
      "Loss at epoch 73000: 6.723452091217041, correct predicted: 1701\n",
      "Loss at epoch 74000: 6.723423480987549, correct predicted: 1701\n",
      "Loss at epoch 75000: 6.723397254943848, correct predicted: 1701\n",
      "Loss at epoch 76000: 6.723369598388672, correct predicted: 1701\n",
      "Loss at epoch 77000: 6.723343849182129, correct predicted: 1703\n",
      "Loss at epoch 78000: 6.723316669464111, correct predicted: 1703\n",
      "Loss at epoch 79000: 6.723289489746094, correct predicted: 1703\n",
      "Loss at epoch 80000: 6.723263740539551, correct predicted: 1703\n",
      "Loss at epoch 81000: 6.72323751449585, correct predicted: 1703\n",
      "Loss at epoch 82000: 6.723211288452148, correct predicted: 1703\n",
      "Loss at epoch 83000: 6.723184585571289, correct predicted: 1703\n",
      "Loss at epoch 84000: 6.7231597900390625, correct predicted: 1704\n",
      "Loss at epoch 85000: 6.723133563995361, correct predicted: 1704\n",
      "Loss at epoch 86000: 6.72310733795166, correct predicted: 1704\n",
      "Loss at epoch 87000: 6.723082542419434, correct predicted: 1704\n",
      "Loss at epoch 88000: 6.723056793212891, correct predicted: 1704\n",
      "Loss at epoch 89000: 6.723031520843506, correct predicted: 1704\n",
      "Loss at epoch 90000: 6.723006248474121, correct predicted: 1705\n",
      "Loss at epoch 91000: 6.7229814529418945, correct predicted: 1705\n",
      "Loss at epoch 92000: 6.722956657409668, correct predicted: 1705\n",
      "Loss at epoch 93000: 6.722930908203125, correct predicted: 1705\n",
      "Loss at epoch 94000: 6.722906589508057, correct predicted: 1705\n",
      "Loss at epoch 95000: 6.72288179397583, correct predicted: 1705\n",
      "Loss at epoch 96000: 6.722856521606445, correct predicted: 1705\n",
      "Loss at epoch 97000: 6.722832202911377, correct predicted: 1705\n",
      "Loss at epoch 98000: 6.722807884216309, correct predicted: 1705\n",
      "Loss at epoch 99000: 6.722784042358398, correct predicted: 1705\n",
      "Loss at epoch 100000: 6.722759246826172, correct predicted: 1705\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100000\n",
    "\n",
    "def train(model, optim, criterion, x, y, epochs=EPOCHS):\n",
    "    for e in range(1, epochs + 1):\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if e%1000==0:\n",
    "            acc = torch.argmax(model.forward(x_train_tensor), axis=1)==y_train_tensor\n",
    "            print(f\"Loss at epoch {e}: {loss.data}, correct predicted: {np.sum(acc.numpy())}\")\n",
    "            \n",
    "    return model\n",
    "\n",
    "model = train(model, optim, criterion, x_train_tensor, y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "processed-stock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4188547136784196"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1675/x_train_tensor.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "collective-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = np.stack(X_test[\"transcription\"].apply(word_vector))\n",
    "Y_test2 = y_test.apply(f).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "dated-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tensor = torch.from_numpy(X_test2).float()\n",
    "y_test_tensor = torch.from_numpy(Y_test2).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "pursuant-affair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = torch.argmax(model.forward(x_test_tensor), axis=1)==y_test_tensor\n",
    "np.sum(acc.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "perceived-indicator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 100])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-contributor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pets",
   "language": "python",
   "name": "pets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
